{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives of sprint 1:\n",
    "\n",
    "- Scaling numeric data and how to transform categorical data.\n",
    "- Padding and Truncating input sequences with varied lengths.\n",
    "- Transforming input sequences into a supervised learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Numeric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     10.0\n",
      "1     20.0\n",
      "2     30.0\n",
      "3     40.0\n",
      "4     50.0\n",
      "5     60.0\n",
      "6     70.0\n",
      "7     80.0\n",
      "8     90.0\n",
      "9    100.0\n",
      "dtype: float64\n",
      "\n",
      "Min: 10.000000, Max: 100.000000\n",
      "\n",
      " [[0.        ]\n",
      " [0.11111111]\n",
      " [0.22222222]\n",
      " [0.33333333]\n",
      " [0.44444444]\n",
      " [0.55555556]\n",
      " [0.66666667]\n",
      " [0.77777778]\n",
      " [0.88888889]\n",
      " [1.        ]]\n",
      "\n",
      " [[ 10.]\n",
      " [ 20.]\n",
      " [ 30.]\n",
      " [ 40.]\n",
      " [ 50.]\n",
      " [ 60.]\n",
      " [ 70.]\n",
      " [ 80.]\n",
      " [ 90.]\n",
      " [100.]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# define contrived series\n",
    "data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "series = Series(data)\n",
    "print(series)\n",
    "\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "\n",
    "# train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "print('\\nMin: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "\n",
    "# normalize the dataset and print\n",
    "normalized = scaler.transform(values)\n",
    "print('\\n', normalized)\n",
    "\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print('\\n', inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0    1.0\n",
      "1    5.5\n",
      "2    9.0\n",
      "3    2.6\n",
      "4    8.8\n",
      "5    3.0\n",
      "6    4.1\n",
      "7    7.9\n",
      "8    6.3\n",
      "dtype: float64\n",
      "\n",
      "Mean: 5.355556, StandardDeviation: 2.712568\n",
      "\n",
      " [[-1.60569456]\n",
      " [ 0.05325007]\n",
      " [ 1.34354035]\n",
      " [-1.01584758]\n",
      " [ 1.26980948]\n",
      " [-0.86838584]\n",
      " [-0.46286604]\n",
      " [ 0.93802055]\n",
      " [ 0.34817357]]\n",
      "\n",
      " [[1. ]\n",
      " [5.5]\n",
      " [9. ]\n",
      " [2.6]\n",
      " [8.8]\n",
      " [3. ]\n",
      " [4.1]\n",
      " [7.9]\n",
      " [6.3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "# define contrived series\n",
    "data = [1.0, 5.5, 9.0, 2.6, 8.8, 3.0, 4.1, 7.9, 6.3]\n",
    "series = Series(data)\n",
    "print('\\n', series)\n",
    "\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "\n",
    "# train the normalization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(values)\n",
    "print('\\nMean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "\n",
    "# normalize the dataset and print\n",
    "standardized = scaler.transform(values)\n",
    "print('\\n', standardized)\n",
    "\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(standardized)\n",
    "print('\\n', inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Categorical Data to Numerical Data\n",
    "\n",
    "This involves two steps:\n",
    "1. Integer Encoding.\n",
    "2. One Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm']\n",
      "\n",
      " [0 0 2 0 1 1 2 0 2]\n",
      "\n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      " ['cold']\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# define example\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm']\n",
    "values = array(data)\n",
    "print('\\n', values)\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print('\\n', integer_encoded)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print('\\n', onehot_encoded)\n",
    "\n",
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "print('\\n', inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Sequences with Varied Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [0 1 2 3]\n",
      " [0 0 0 1]]\n",
      "\n",
      " [[1 2 3 4]\n",
      " [1 2 3 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# define sequences\n",
    "sequences = [[1, 2, 3, 4],\n",
    "             [1, 2, 3],\n",
    "             [1]]\n",
    "\n",
    "# pre-sequence padding\n",
    "padded = pad_sequences(sequences)\n",
    "print(padded)\n",
    "\n",
    "# post-sequence padding\n",
    "padded = pad_sequences(sequences, padding = 'post')\n",
    "print('\\n', padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [2 3]\n",
      " [0 1]]\n",
      "\n",
      " [[1 2]\n",
      " [1 2]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# pre-sequence truncation\n",
    "truncated = pad_sequences(sequences, maxlen = 2)\n",
    "print(truncated)\n",
    "\n",
    "# post-sequence truncation\n",
    "truncated = pad_sequences(sequences, maxlen = 2, truncating = 'post')\n",
    "print('\\n', truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform time series data into a supervised learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   t\n",
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "3  3\n",
      "4  4\n",
      "5  5\n",
      "6  6\n",
      "7  7\n",
      "8  8\n",
      "9  9\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "# define the sequence\n",
    "df = DataFrame()\n",
    "df['t'] = [x for x in range(10)]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   t  t-1\n",
      "0  0  NaN\n",
      "1  1  0.0\n",
      "2  2  1.0\n",
      "3  3  2.0\n",
      "4  4  3.0\n",
      "5  5  4.0\n",
      "6  6  5.0\n",
      "7  7  6.0\n",
      "8  8  7.0\n",
      "9  9  8.0\n",
      "\n",
      "    t  t-1  t+1\n",
      "0  0  NaN  1.0\n",
      "1  1  0.0  2.0\n",
      "2  2  1.0  3.0\n",
      "3  3  2.0  4.0\n",
      "4  4  3.0  5.0\n",
      "5  5  4.0  6.0\n",
      "6  6  5.0  7.0\n",
      "7  7  6.0  8.0\n",
      "8  8  7.0  9.0\n",
      "9  9  8.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# shift forward\n",
    "df['t-1'] = df['t'].shift(1)\n",
    "print(df)\n",
    "\n",
    "# shift backward\n",
    "df['t+1'] = df['t'].shift(-1)\n",
    "print('\\n', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives of sprint 2:\n",
    "\n",
    "- Defining an LSTM model, including how to reshape your data for the required 3D input.\n",
    "- Fitting and evaluating LSTM model and use it to make predictions on new data.\n",
    "- Taking fine-grained control over the internal state in the model and when it is reset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.LSTM(2))  # LSTM hidden layer with 2 memory cells\n",
    "model.add(layers.Dense(1))  # Dense output layer with 1 neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = [layers.LSTM(2), layers.Dense(1)]\n",
    "model = Sequential(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first hidden layer in the network must define the number of inputs to expect, e.g. the shape of the input layer. Input must be three-dimensional, comprised of samples, time steps and features in that order.\n",
    "\n",
    "- Samples. These are the rows in your data. One sample may be one sequence.\n",
    "- Time steps. These are the past observations for a feature, such as lag variables.\n",
    "- Features. These are columns in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7\n",
      "Number of time steps: 2\n",
      "Number of features per time step: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([[1, 2],\n",
    "                 [2, 3],\n",
    "                 [3, 4],\n",
    "                 [4, 5],\n",
    "                 [5, 6],\n",
    "                 [6, 7],\n",
    "                 [7, 8]])\n",
    "\n",
    "out = [3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "data = data.reshape((data.shape[0], data.shape[1], 1))\n",
    "\n",
    "print('Number of samples:', data.shape[0])\n",
    "print('Number of time steps:', data.shape[1])\n",
    "print('Number of features per time step:', data.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **input shape** argument that expects a tuple containing the number of\n",
    "**time steps** and the **number of features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(5, input_shape = (2,1)))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd', loss= 'mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
